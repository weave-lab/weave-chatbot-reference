{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7bc942c",
   "metadata": {},
   "source": [
    "# LLM Evaluations for RAG Systems\n",
    "\n",
    "Given the stochastic nature of Large Language Models (LLMs), establishing robust evaluation criteria is crucial for building confidence in their performance. For Retrieval-Augmented Generation (RAG) systems, comprehensive evaluation requires assessing both the retrieval and generation components to ensure system reliability and accuracy.\n",
    "\n",
    "## Background\n",
    "\n",
    "In the 101 RAG Hands-On Training, we demonstrated how LLM Judges can be utilized to evaluate RAG systems effectively. \n",
    "\n",
    "- **[Evaluation Documentation Reference](https://docs.google.com/document/d/1Rg1QXZ5Cg0aX8hYvRrvevY1uz6lPpZkaasoqW7Pcm9o/edit?tab=t.0#heading=h.jjijsv4v12qe)** \n",
    "- **[Evaluation Code Reference](./../workshop-101/eval_rag.py)** \n",
    "\n",
    "## Workshop Objectives\n",
    "\n",
    "In this notebook, we will explore advanced evaluation techniques using two powerful libraries:\n",
    "- **[Ragas](https://github.com/explodinggradients/ragas)** \n",
    "- **[Google Gen AI Evaluation Service](https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-overview)** \n",
    "\n",
    "These tools will help you implement systematic evaluation workflows to measure and improve your RAG system's performance across various metrics and use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c58e64c",
   "metadata": {},
   "source": [
    "## Ragas\n",
    "\n",
    "Ragas is an open-source library published under the Apache 2.0 license that provides a comprehensive toolkit for evaluating and optimizing LLM applications. It offers specialized metrics and evaluation frameworks making it easier to assess LLM generations\n",
    "\n",
    "### Installation\n",
    "\n",
    "You can install Ragas using UV (our preferred package manager):\n",
    "\n",
    "```bash\n",
    "uv add ragas\n",
    "```\n",
    "\n",
    "Alternatively, you can install it with pip:\n",
    "\n",
    "```bash\n",
    "pip install ragas\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af69fd6d",
   "metadata": {},
   "source": [
    "### Setting up Ragas\n",
    "\n",
    "Install the Langchain wrapper for Vertex AI to use Vertex AI models in Ragas:\n",
    "\n",
    "```bash\n",
    "uv add langchain-google-vertexai\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0bb01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "# Define global constants for project and location\n",
    "PROJECT_ID = \"weave-ai-sandbox\"\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(\n",
    "    ChatVertexAI(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        project=PROJECT_ID,\n",
    "        location=LOCATION,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6041538e",
   "metadata": {},
   "source": [
    "### Retriever Evaluation \n",
    "\n",
    "In the 101 workshop, we demonstrated how the retrieval system's ability to rank relevant chunks can be evaluated using context precision. This evaluation was based on the Ragas metric called Context Precision.\n",
    "\n",
    "**References:**\n",
    "- Code reference to base implementation: [Base implementation](./../workshop-101/eval_rag.py#115)\n",
    "- Ragas documentation: [Context Precision metric](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/context_precision/)\n",
    "\n",
    "Before implementing the code, take a moment to go through the Ragas documentation to understand how they calculate context precision. \n",
    "\n",
    "Now, let's implement the Ragas version of this metric to evaluate retrieval performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab538761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import SingleTurnSample\n",
    "from ragas.metrics import LLMContextPrecisionWithoutReference\n",
    "\n",
    "context_precision = LLMContextPrecisionWithoutReference(llm=evaluator_llm)\n",
    "\n",
    "sample = SingleTurnSample(\n",
    "    user_input=\"Where is the Eiffel Tower located?\",\n",
    "    response=\"The Eiffel Tower is located in Paris.\",\n",
    "    retrieved_contexts=[\"The Eiffel Tower is located in Paris.\"],\n",
    ")\n",
    "\n",
    "\n",
    "await context_precision.single_turn_ascore(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weave-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
